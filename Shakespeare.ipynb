{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tensor\n",
    "import numpy as np\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get Train file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fpath = tensor.keras.utils.get_file('shakespeare.txt',\n",
    "                                    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "ftext = open(fpath,\"rb\").read().decode(encoding=\"utf-8\").lower()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "open : open file and return stream , rb : r:open for reading ;b: retrieve in binary mode\n",
    "read : return file content, para default = -1 => whole file\n",
    "decode: decode the UTF-8 stream into readable string\n",
    "lower :change test to lowercase ( for simplicity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Prep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "# train_text =ftext[300000:800000]\n",
    "#Use certain subset of data to train\n",
    "char = sorted(set(ftext))\n",
    "#set:  no repetition , unchangeable\n",
    "char_index = dict((c,i) for i, c in enumerate(char)) # Character to index\n",
    "index_char = dict((i,c) for i,c in enumerate(char)) # index to Character\n",
    "\n",
    "SEQ_LEN = 40\n",
    "STEP_SIZE = 3 # next sentence\n",
    "sentences= [] # list of sentences\n",
    "next_char=[] # next char in relation to  index of sentences\n",
    "\n",
    "#store into lists\n",
    "for i  in range(0,len(ftext)-SEQ_LEN,STEP_SIZE):\n",
    "    sentences.append(ftext[i:i+SEQ_LEN])\n",
    "    next_char.append(ftext[i+SEQ_LEN])\n",
    "\n",
    "x = np.zeros((len(sentences),SEQ_LEN,len(char)),dtype=bool)\n",
    "#zeros: array of zeros , 3-dim , data type = bool\n",
    "y = np.zeros((len(sentences), len(char)),dtype = bool)\n",
    "# 2-dim\n",
    "\n",
    "for i, s in enumerate(sentences):\n",
    "    for j,c in enumerate(s):\n",
    "        x[i,j,char_index[c]] = 1 # 3_Dim array to represent whether a character is present; array: [sentence number ,  character position in sentence, which unique charcter it is from the char array ]\n",
    "    y[i,char_index[next_char[i]]] = 1 # 2-dim  array to relate the sentence and the next character\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Recurrent Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\sidmo\\anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1453/1453 [==============================] - 152s 101ms/step - loss: 1.9258\n",
      "Epoch 2/4\n",
      "1453/1453 [==============================] - 158s 109ms/step - loss: 1.5930\n",
      "Epoch 3/4\n",
      "1453/1453 [==============================] - 133s 91ms/step - loss: 1.5173\n",
      "Epoch 4/4\n",
      "1453/1453 [==============================] - 122s 84ms/step - loss: 1.4790\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x17ba3be15a0>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape = (SEQ_LEN,len(char)))) #long short term memory layer # 128 neurons, set to True\n",
    "model.add(Dense(len(char))) #increase complexity\n",
    "model.add(Activation(\"softmax\")) # results add to one\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=RMSprop(lr=0.01))\n",
    "model.fit(x,y,batch_size=256,epochs=4)  #batch size : samples per gradient update, epoch: num iterations over entire x, y\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helper to generate reasonable text from Keras Tutorial to check risk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def sample(predictions, temperature =1.0):\n",
    "    predictions = np.asarray(predictions).astype('float64')\n",
    "    predictions = np.log(predictions)/temperature\n",
    "    exp_preds = np.exp(predictions )\n",
    "    predictions = exp_preds/ np.sum (exp_preds)\n",
    "    probas = np.random.multinomial(1,predictions,1)\n",
    "    return np.argmax(probas)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate Text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def text_gen(length,temperature):\n",
    "    start_index = random.randint(0,len(ftext) - SEQ_LEN -1) # choose random starting position\n",
    "    gen =''\n",
    "    sentence = ftext[start_index:start_index +SEQ_LEN] # get sentence\n",
    "    gen += sentence\n",
    "    for i in range(length): # run loop to get characters\n",
    "         x_pred = np.zeros((1,SEQ_LEN,len(char))) # predicted array\n",
    "         for t, c in enumerate(sentence):\n",
    "             x_pred[0,t,char_index[c]] = 1\n",
    "         predictions = model.predict(x_pred, verbose=0)[0] #predict next char\n",
    "         next_index = sample(predictions, temperature)\n",
    "         next_character = index_char[next_index]\n",
    "         gen += next_character\n",
    "         sentence = sentence[1:] +next_character\n",
    "    return gen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "\"e 'ever' last?\\n\\nKING RICHARD III:\\nSweetly so so have the contraint that shall\\nto the consuler and this son and the son\\nTo stay the sending of the brother the house.\\n\\nCLARENCE:\\nI am the death that the sense that the state\\nThat the wars that will be the countervised\\nTo the son that the way to the son and sets\\nThat the state of the counter'd\""
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gen(300,0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
